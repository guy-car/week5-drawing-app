# Goal
Implement 4 demo-ready features for the drawing app in order of safety and impact, with conservative testing and backup strategies. Target completion in 1 hour with ability to revert if features destabilize the app.

# Action Plan

## **COMMIT CHECKPOINT** (Do this FIRST!)
- **Files:** All current changes
- **Action:** Commit current state with message "Pre-demo checkpoint - stable baseline"
- **Purpose:** Enable quick `git reset --hard HEAD~1` if any feature breaks the app

## âœ… **FEATURE 1: LOADING MESSAGE (PRIORITY 1)** - COMPLETED
**Risk Level:** ðŸŸ¢ Very Low | **Impact:** ðŸ”¥ High | **Files:** `App.tsx`

### What We Implemented:
1. Added "[Incoming transmission...]" loading message with sci-fi glow effect
2. Message appears when alien button is clicked
3. Message disappears as soon as first AI stroke appears
4. Used layered text components for glow effect
5. Added fade animation for smooth transitions
6. Positioned message in top third of canvas

### Technical Implementation:
1. Added loading message using `Animated.View` and `CustomText`
2. Created glow effect using layered text with different opacities
3. Used `hasSeenFirstCommandRef` to track first AI command
4. Implemented reliable state management in `proceedWithAPICallHandler`
5. Added fade animation using `Animated.Value`

### Testing Completed:
- âœ… Loading appears on alien button click
- âœ… Disappears immediately on first AI stroke
- âœ… Works reliably on subsequent AI interactions
- âœ… Smooth fade animations
- âœ… No interference with canvas interaction

### Position Control:
The message position can be adjusted in `App.tsx` styles:
```typescript
loadingContainer: {
  position: 'absolute',
  top: '25%',    // Adjust this value to move message up/down
  left: 0,
  right: 0,
  alignItems: 'center',
  justifyContent: 'center',
  zIndex: 100,
},
```

---

## **FEATURE 2: SAVE TO CAMERA ROLL (PRIORITY 2)** - 20 minutes
**Risk Level:** ðŸŸ¡ Low-Medium | **Impact:** ðŸ”¥ High | **Files:** `package.json`, `app.json`, `App.tsx`

### Implementation Steps:
1. **Install dependency** (`package.json`)
   ```bash
   npx expo install expo-media-library
   ```

2. **Add permissions** (`app.json`)
   ```json
   "permissions": [
     "CAMERA_ROLL",
     "WRITE_EXTERNAL_STORAGE"
   ]
   ```

3. **Import and setup** (`App.tsx` top imports)
   ```typescript
   import * as MediaLibrary from 'expo-media-library';
   ```

4. **Add save function** (`App.tsx` after existing functions)
   ```typescript
   const handleSaveToLibrary = async () => {
     try {
       // Request permission
       const { status } = await MediaLibrary.requestPermissionsAsync();
       if (status !== 'granted') {
         Alert.alert('Permission needed', 'Camera roll access required to save');
         return;
       }

       // Export canvas
       const imageUri = await canvasRef.current?.exportCanvas();
       if (!imageUri) {
         Alert.alert('Error', 'Failed to export canvas');
         return;
       }

       // Save to library
       await MediaLibrary.saveToLibraryAsync(imageUri);
       Alert.alert('Success', 'Drawing saved to camera roll!');
     } catch (error) {
       console.error('Save error:', error);
       Alert.alert('Error', 'Failed to save drawing');
     }
   };
   ```

5. **Add save button** (`App.tsx` in buttonGroup around line 270)
   ```typescript
   <GlowButton 
     style={[styles.iconButton, !canvasEmpty && styles.activeButton, canvasEmpty && styles.disabledButton]} 
     glowLevel={!canvasEmpty ? 'medium' : 'none'}
     onPress={handleSaveToLibrary}
     disabled={canvasEmpty}
   >
     <DownloadSimple
       size={24}
       color={!canvasEmpty ? "#FFFFFF" : "#666666"}
       weight="bold"
     />
   </GlowButton>
   ```

6. **Import DownloadSimple icon** (`App.tsx` imports)
   ```typescript
   import { ..., DownloadSimple } from 'phosphor-react-native';
   ```

### Testing:
- Test save with drawing (should succeed)
- Test save with empty canvas (should be disabled)
- Test permission denial (should show alert)
- Verify saved image appears in camera roll
- Test multiple saves (should work repeatedly)

### Backup Strategy:
- If permission fails: Check `app.json` permissions
- If export fails: Check `exportCanvas` function
- If save fails: Check MediaLibrary import
- **Revert approach:** Remove MediaLibrary import, remove save button, remove permission from app.json

---

## **FEATURE 3: ALIENS CHOOSE COLORS/WIDTH (PRIORITY 3)** - 25 minutes
**Risk Level:** ðŸŸ¡ Medium | **Impact:** ðŸ”¥ High | **Files:** `src/api/openai/riffOnSketch.ts`, `src/api/openai/types.ts`, `components/DrawingCanvas.tsx`

### Implementation Steps:
1. **Update AI prompt** (`src/api/openai/riffOnSketch.ts` around line 50)
   - Find the prompt text in the riffOnSketch function
   - Modify to include color/width selection instructions

2. **Add color selection to prompt** (`src/api/openai/riffOnSketch.ts`)
   ```typescript
   text: `You are an alien intelligence responding to a human drawing transmission.

   ALIEN DRAWING STYLE:
   - Choose your own alien colors from these options: ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7', '#dda0dd', '#98fb98', '#f0e68c']
   - Choose your own stroke width from these options: [2, 4, 6, 8, 12, 16]
   - Each stroke should maintain consistent color and width
   - Use colors that feel otherworldly and mysterious

   IF the human drawing contains recognizable shapes:
   - Circle around 1-2 elements using your chosen alien color
   - Add arrows pointing to details using same color
   - Use flowing, organic circles and curved arrows

   OTHERWISE create mysterious alien art:
   - Draw strange symbols using your chosen color
   - Create flowing energy patterns
   - Add crystalline structures
   - Use spirals and tendrils

   IMPORTANT: Start each new drawing path with a color command:
   {"type": "setColor", "color": "#chosen_color"}
   {"type": "setWidth", "width": chosen_width}
   Then continue with your drawing commands.

   COMMANDS: Generate 15-20 drawing commands...`
   ```

3. **Update command schema** (`src/api/openai/types.ts`)
   ```typescript
   const setColorSchema = z.object({
     type: z.literal('setColor'),
     color: z.string().regex(/^#[0-9a-fA-F]{6}$/)
   });

   const setWidthSchema = z.object({
     type: z.literal('setWidth'),
     width: z.number().int().min(2).max(20)
   });

   export const commandSchema = z.union([
     moveToSchema,
     lineToSchema,
     // ... existing schemas
     setColorSchema,
     setWidthSchema,
   ]);
   ```

4. **Handle new commands** (`components/DrawingCanvas.tsx` in addAIPath function)
   ```typescript
   let currentColor = selectedColor;
   let currentWidth = strokeWidthRef.current;

   commands.forEach(command => {
     switch (command.type) {
       case 'setColor':
         currentColor = command.color;
         break;
       case 'setWidth':
         currentWidth = command.width;
         break;
       // ... existing cases
     }
   });

   // Use currentColor and currentWidth in stroke creation
   const stroke: Stroke = { 
     path: aiPath, 
     commands,
     color: currentColor,  // Use AI-chosen color
     strokeWidth: currentWidth // Use AI-chosen width
   };
   ```

### Testing:
- Test AI response with varied colors
- Test AI response with varied widths
- Verify colors are visually distinct from user colors
- Test with multiple AI interactions
- Verify old functionality still works

### Backup Strategy:
- If AI doesn't use colors: Check prompt formatting
- If colors don't render: Check stroke creation logic
- If width doesn't work: Check command schema
- **Revert approach:** Restore original prompt text, remove new command types

---

## **FEATURE 4: TWO-FINGER MOVE, THREE-FINGER ZOOM (PRIORITY 4)** - 25 minutes
**Risk Level:** ðŸ”´ Medium-High | **Impact:** ðŸŸ¡ Medium | **Files:** `components/DrawingCanvas.tsx`, `App.tsx`

### Implementation Steps:
1. **Backup current gesture system** 
   - Copy current `panGesture` implementation
   - Note current `minPointers(2)` setting

2. **Update pan gesture** (`components/DrawingCanvas.tsx` around line 455)
   ```typescript
   const panGesture = Gesture.Pan()
     .enabled(true)  // Always enabled, not mode-dependent
     .minPointers(2)  // Exactly 2 fingers for pan
     .maxPointers(2)  // Exactly 2 fingers for pan
     .onStart(() => {
       startTranslateX.value = translateX.value;
       startTranslateY.value = translateY.value;
     })
     .onUpdate((e) => {
       const newX = startTranslateX.value + e.translationX;
       const newY = startTranslateY.value + e.translationY;
       
       const bounds = getPanBounds(scale.value);
       const clampedX = Math.max(-bounds.maxX, Math.min(bounds.maxX, newX));
       const clampedY = Math.max(-bounds.maxY, Math.min(bounds.maxY, newY));
       
       translateX.value = clampedX;
       translateY.value = clampedY;
     })
     .runOnJS(true);
   ```

3. **Add pinch gesture** (`components/DrawingCanvas.tsx` after panGesture)
   ```typescript
   const pinchGesture = Gesture.Pinch()
     .enabled(true)
     .minPointers(3)  // Exactly 3 fingers for zoom
     .maxPointers(3)  // Exactly 3 fingers for zoom
     .onUpdate((e) => {
       const newScale = Math.max(MIN_ZOOM, Math.min(MAX_ZOOM, scale.value * e.scale));
       
       const bounds = getPanBounds(newScale);
       const clampedX = Math.max(-bounds.maxX, Math.min(bounds.maxX, translateX.value));
       const clampedY = Math.max(-bounds.maxY, Math.min(bounds.maxY, translateY.value));
       
       scale.value = newScale;
       translateX.value = clampedX;
       translateY.value = clampedY;
       onZoomChange(newScale);
     })
     .runOnJS(true);
   ```

4. **Combine gestures** (`components/DrawingCanvas.tsx` around line 467)
   ```typescript
   const combinedGesture = Gesture.Simultaneous(panGesture, pinchGesture);
   ```

5. **Update GestureDetector** (`components/DrawingCanvas.tsx` around line 551)
   ```typescript
   <GestureDetector gesture={combinedGesture}>
   ```

6. **Remove mode dependency** (`App.tsx`)
   - Remove move/draw mode button (optional)
   - Or keep it for feedback but don't use for gesture enabling

### Testing:
- Test single finger drawing (should work)
- Test two-finger pan (should pan canvas)
- Test three-finger pinch (should zoom)
- Test gesture combinations
- Test drawing while panned/zoomed
- Test boundaries and limits

### Backup Strategy:
- If gestures conflict: Check minPointers/maxPointers
- If drawing breaks: Check gesture enablement
- If pan/zoom stops working: Check gesture combination
- **Revert approach:** Restore original panGesture, remove pinchGesture, restore mode-dependent enabling

---

## **TESTING PROTOCOL**

### After Each Feature:
1. **Basic functionality test** - Core feature works
2. **Integration test** - Doesn't break existing features
3. **Edge case test** - Handles errors gracefully
4. **Performance test** - No significant slowdown

### Before Demo:
1. **Complete workflow test** - Draw â†’ AI â†’ Save â†’ Clear
2. **Gesture test** - All touch interactions work
3. **Loading test** - All loading states appear/disappear
4. **Error handling test** - Graceful failures

### Emergency Revert Strategy:
```bash
# If any feature breaks the app:
git reset --hard HEAD~1  # Back to pre-demo checkpoint
git clean -fd           # Remove any new files
```

---

## **RISK MITIGATION**

### High-Risk Areas:
1. **Gesture System** - Most likely to break existing functionality
2. **AI Command Processing** - Could break AI responses
3. **File Permissions** - Could block save functionality

### Safety Measures:
1. **Test incrementally** - One feature at a time
2. **Commit frequently** - After each working feature
3. **Keep original code** - Comment out, don't delete
4. **Test on device** - Not just simulator

### Success Metrics:
- âœ… All 4 features working
- âœ… No existing functionality broken
- âœ… App stable for demo
- âœ… Graceful error handling

---

**Total Estimated Time:** 80 minutes (with 20 minutes buffer)
**Conservative Approach:** Complete features 1-2 guaranteed, attempt 3-4 if time permits
**Backup Plan:** Revert to checkpoint if any feature destabilizes the app 